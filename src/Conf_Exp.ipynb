{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Confusable Expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "from cytoolz import concat, sliding_window\n",
    "\n",
    "%precision 2\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "\n",
    "    import ipytest\n",
    "\n",
    "    ipytest.autoconfig()\n",
    "\n",
    "    def init_test():\n",
    "        ipytest.clean()\n",
    "\n",
    "    def run_test():\n",
    "        ipytest.run()\n",
    "\n",
    "except NameError:\n",
    "\n",
    "    def init_test():\n",
    "        pass\n",
    "\n",
    "    def run_test():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = [line.split() for line in gzip.open('../data/confuse.txt.gz','rt')]\n",
    "random.shuffle(data)\n",
    "\n",
    "sentences_train = data[:50000]\n",
    "sentences_test = data[50000:55000]\n",
    "\n",
    "conf_set = [\"their\", \"there\", \"they're\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to try several similar, but slightly different approaches. Let's start by defining a general `Confuser` class that contains the logic for testing a method but doesn't instantiate any particular method. For extra reference, [this](http://introtopython.org/classes.html) might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Confuser:\n",
    "    def __init__(self, confusable_set):\n",
    "        self.confusable_set = confusable_set\n",
    "\n",
    "    def preprocess(self, sentence):\n",
    "        return sentence\n",
    "\n",
    "    def train(self, training_corpus):\n",
    "        pass\n",
    "\n",
    "    def guess(self, sentence, position):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eval(self, test_corpus):\n",
    "        \"\"\"Run a confusable-guesser over a test corpus and report the accuracy.\"\"\"\n",
    "        total = 0\n",
    "        right = 0\n",
    "        for sentence in test_corpus:\n",
    "            sentence = self.preprocess(sentence)\n",
    "            for i, w in enumerate(sentence):\n",
    "                if w in self.confusable_set:\n",
    "                    guess = self.guess(sentence, i)\n",
    "                    if guess == sentence[i]:\n",
    "                        right += 1\n",
    "                    total += 1\n",
    "        return right / total * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Guessing\n",
    "\n",
    "If we know nothing at all about the problem other than the fact that we have three confusable words, we can randomly guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class RandomConfuser(Confuser):\n",
    "    def guess(self, line, i):\n",
    "        \"\"\"Choose one of the confusable set at random\"\"\"\n",
    "        return random.choice(self.confusable_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are three choices, then we'd expect to guess correctly about 33% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.63"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_confuser = RandomConfuser(conf_set)\n",
    "random_confuser.eval(sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Confuser\n",
    "\n",
    "We can definitely do better than random guessing. One piece of information we can get from our training corpus is the relative frequencies of *there, they're,* and *their*. If they aren't all equally common (which they aren't), we can beat random guessing by always going with the most frequent option.\n",
    "\n",
    "This might be inefficient and the worst method possible, but it often gives surprisingly good results. This is in part due to Zipf's Law, which tells us that there are a few very frequent things and lots of infrequent things. In other words, the frequencies of confusable items can be very uneven, and the more uneven the probabilities the better we do with a default choice.\n",
    "\n",
    "Since this method is simple, we can use it to establish a *baseline* score that tells us how well we do if we do almost nothing. This gives a sense of how difficult a problem is. Any fancier solutions can be evaluated against the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DefaultConfuser(Confuser):\n",
    "\n",
    "    def preprocess(self, sentence):\n",
    "        \"\"\"Lowercase sentence.\"\"\"\n",
    "        return [w.lower() for w in sentence]\n",
    "\n",
    "    def train(self, train_corpus):\n",
    "        \"\"\"Find the most common member of the confusion set in the training corpus.\"\"\"\n",
    "        train_corpus = [self.preprocess(sentence) for sentence in train_corpus]\n",
    "        target_counts = Counter(\n",
    "            w for w in concat(train_corpus) if w in self.confusable_set\n",
    "        )\n",
    "        self.default_guess = target_counts.most_common()[0][0]\n",
    "\n",
    "    def guess(self, line, i):\n",
    "        \"\"\"Always guess the most frequent member of the confusion set.\"\"\"\n",
    "        return self.default_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case, going with a default is better than random guessing, but not by all that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = DefaultConfuser(conf_set)\n",
    "baseline.train(sentences_train)\n",
    "baseline.eval(sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Model\n",
    "\n",
    "With the baseline in mind, we can try using a **Bigram Language Model** to solve the confusables problem. Let's say we see the sequence *in their house* and we want to know if that's correct. We can use a language model to compare $P(\\textit{in, their, house})$ to $P(\\textit{in, there, house})$ and $P(\\textit{in, they're, house})$. Whichever sequence has the highest probability is the one with the correct member of the confusion set (we hope!).\n",
    "\n",
    "To start, by the chain rule we have:\n",
    "\n",
    "$$P(\\textit{in, their, house})=P(\\textit{in})\\times P(\\textit{their}|\\textit{in})\\times P(\\textit{house}|\\textit{their,in})$$\n",
    "\n",
    "We can simplify this two ways. First, since all the sequences we're testing start with *in*, we can leave out the $P(in)$ term without changing the relative order of the 3 sequences. Second, if we assume a first order Markov Model (=bigrams),  we only need to consider one word of context.\n",
    "\n",
    "These two changes get us:\n",
    "\n",
    "$$\\begin{align}\n",
    "P(\\textit{their, house}|\\textit{in})&=P(\\textit{their}|\\textit{in})\\times P(\\textit{house}|\\textit{their})\\\\\n",
    "&=\\frac{C_B(\\textit{in their})}{C_U(\\textit{in})}\\times\\frac{C_B(\\textit{their house})}{C_U(\\textit{their})}\n",
    "\\end{align}$$\n",
    "\n",
    "where $C_B$ and $C_U$ are bigram and unigram frequencies in the training corpus. We repeat this for *there* and *they're* and use the one with the highest probability. If the probability of all three options turns out to be zero, then we'll fall back on the most frequent overall choice, as we did for the default confuser. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BigramConfuser(DefaultConfuser):\n",
    "    def preprocess(self, sentence):\n",
    "        \"\"\"Normalize sentence and add filler tokens <s> and </s>\"\"\"\n",
    "        return [\"<s>\"] + [w.lower() for w in sentence] + [\"</s>\"]\n",
    "\n",
    "    def get_unigram_counts(self, train_corpus):\n",
    "        self.unigrams = Counter(concat(train_corpus))\n",
    "\n",
    "    def get_bigram_counts(self, train_corpus):\n",
    "        self.bigrams = Counter(sliding_window(2, concat(train_corpus)))\n",
    "\n",
    "    def get_default_guess(self):\n",
    "        self.default_guess = max((self.unigrams[w], w) for w in self.confusable_set)[1]\n",
    "\n",
    "    def train(self, train_corpus):\n",
    "        \"\"\"Count bigram and unigram frequencies in the training corpus.\"\"\"\n",
    "        train_corpus = [self.preprocess(sentence) for sentence in train_corpus]\n",
    "        self.get_unigram_counts(train_corpus)\n",
    "        self.get_bigram_counts(train_corpus)\n",
    "        self.get_default_guess()\n",
    "\n",
    "    def guess(self, sentence, i):\n",
    "        \"\"\"Find the guess that maximizes the probability of the sequence\"\"\"\n",
    "        best_p = 0.0\n",
    "        best_guess = self.default_guess\n",
    "        for guess in self.confusable_set:\n",
    "            p = self.prob(guess, sentence, i)\n",
    "            if p > best_p:\n",
    "                best_p = p\n",
    "                best_guess = guess\n",
    "        return best_guess\n",
    "\n",
    "    def prob(self, guess, sentence, i):\n",
    "        \"\"\"Calculate the probability of a guess in context.\"\"\"\n",
    "        try:\n",
    "            p1 = self.bigrams[sentence[i - 1], guess] / self.unigrams[sentence[i - 1]]\n",
    "            p2 = self.bigrams[guess, sentence[i + 1]] / self.unigrams[guess]\n",
    "            return p1 * p2\n",
    "        except ZeroDivisionError:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigram model performs much better than the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_confuser = BigramConfuser(conf_set)\n",
    "bigram_confuser.train(sentences_train)\n",
    "bigram_confuser.eval(sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Error Reduction** is a measure of how much better one model is than another. In this case, the bigram model reduces the error rate of the default model by about 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_error = 1 - baseline.eval(sentences_test)\n",
    "bigram_error = 1 - bigram_confuser.eval(sentences_test)\n",
    "(bigram_error - baseline_error) / baseline_error * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difficulty with implementing language models is that it's hard to know what the \"right\" answer is. A small error in our code might give us a lower accuracy, but how would we know? For testing purposes, it can be helpful to create tiny training and test sets that are small enough that we can do the relevant calculations by hand and then confirm that our code comes up with the same answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                               [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m14 passed\u001b[0m\u001b[32m in 0.15s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "DATA = [\n",
    "    \"The jury did not elaborate , but it added that `` there should be periodic surveillance of the pricing practices of the concessionaires for the purpose of keeping the prices reasonable '' .\",\n",
    "    \"Despite the warning , there was a unanimous vote to enter a candidate , according to Republicans who attended .\",\n",
    "    \"When the crowd was asked whether it wanted to wait one more term to make the race , it voted no -- and there were no dissents .\",\n",
    "    \"A highway department source said there also is a plan there to issue some $3 million to $4 million worth of rural roads authority bonds for rural road construction work .\",\n",
    "    \"A highway department source said there also is a plan there to issue some $3 million to $4 million worth of rural roads authority bonds for rural road construction work .\",\n",
    "    \"Pelham said Sunday night there was research being done on whether the `` quickie '' vote on the increase can be repealed outright or whether notice would have to first be given that reconsideration of the action would be sought .\",\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def my_bigram_confuser():\n",
    "    conf = BigramConfuser([\"their\", \"there\", \"they're\"])\n",
    "    conf.train(s.split() for s in DATA)\n",
    "    return conf\n",
    "\n",
    "\n",
    "def test_bigram_confuser_default(my_bigram_confuser):\n",
    "    assert my_bigram_confuser.default_guess == \"there\"\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"gram,count\", [(\"<s>\", 6), (\"the\", 11), (\"to\", 9), (\"pelham\", 1), (\"zippy\", 0)]\n",
    ")\n",
    "def test_bigram_confuser_uni(my_bigram_confuser, gram, count):\n",
    "    assert my_bigram_confuser.unigrams[gram] == count\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"gram,count\",\n",
    "    [\n",
    "        ((\"<s>\", \"<s>\"), 0),\n",
    "        ((\"</s>\", \"<s>\"), 5),\n",
    "        ((\"asked\", \"whether\"), 1),\n",
    "        ((\"the\", \"pinhead\"), 0),\n",
    "    ],\n",
    ")\n",
    "def test_bigram_confuser_bi(my_bigram_confuser, gram, count):\n",
    "    assert my_bigram_confuser.bigrams[gram] == count\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"guess,seq,p\",\n",
    "    [\n",
    "        (\"there\", (\"said\", \"X\", \"also\"), 0.1667),\n",
    "        (\"there\", (\"said\", \"X\", \"should\"), 0.0833),\n",
    "        (\"their\", (\"said\", \"X\", \"should\"), 0.0),\n",
    "        (\"their\", (\"before\", \"X\", \"after\"), 0.0),\n",
    "    ],\n",
    ")\n",
    "def test_bigram_confuser_prob(my_bigram_confuser, guess, seq, p):\n",
    "    assert my_bigram_confuser.prob(guess, seq, 1) == pytest.approx(p, rel=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing\n",
    "\n",
    "We can improve our bigram model by smoothing, and the simplest method for smoothing is to simply add one to every count, giving us:\n",
    "\n",
    "$$\n",
    "P(\\textit{their, house}|\\textit{in})=\\frac{C_B(\\textit{in their})+1}{C_U(\\textit{in})+V}\\times\\frac{C_B(\\textit{their house})+1}{C_U(\\textit{their})+V}\n",
    "$$\n",
    "\n",
    "where $V$ is the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BigramAddOneConfuser(BigramConfuser):\n",
    "    def prob(self, guess, sentence, i):\n",
    "        # Size of vocabulary\n",
    "        V = len(self.unigrams)\n",
    "\n",
    "        # Calculate smoothed probability\n",
    "        bigram_p1_num = self.bigrams[(sentence[i - 1], guess)] + 1\n",
    "        bigram_p1_den = self.unigrams[sentence[i - 1]] + V\n",
    "        p1 = bigram_p1_num / bigram_p1_den\n",
    "        \n",
    "        # Calculate smoothed probability\n",
    "        bigram_p2_num = self.bigrams[(guess, sentence[i + 1])] + 1\n",
    "        bigram_p2_den = self.unigrams[guess] + V\n",
    "        p2 = bigram_p2_num / bigram_p2_den\n",
    "        \n",
    "        # Return product\n",
    "        return p1 * p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram1_confuser = BigramAddOneConfuser(conf_set)\n",
    "bigram1_confuser.train(sentences_train)\n",
    "bigram1_confuser.eval(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reduction vs. baseline model = 72.87%\n",
      "Error reduction vs. bigram model   = 21.62%\n"
     ]
    }
   ],
   "source": [
    "bigram1_error = 1 - bigram1_confuser.eval(sentences_test)\n",
    "print(\n",
    "    f\"Error reduction vs. baseline model = {(bigram1_error - baseline_error) / baseline_error * 100:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Error reduction vs. bigram model   = {(bigram1_error - bigram_error) / bigram_error * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "@pytest.fixture\n",
    "def my_bigram1_confuser():\n",
    "    conf = BigramAddOneConfuser([\"their\", \"there\", \"they're\"])\n",
    "    conf.train(s.split() for s in DATA)\n",
    "    return conf\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"guess,seq,p\",\n",
    "    [\n",
    "        (\"there\", (\"said\", \"X\", \"also\"), 0.0008090),\n",
    "        (\"there\", (\"said\", \"X\", \"should\"), 0.0005393),\n",
    "        (\"their\", (\"said\", \"X\", \"should\"), 9.7087e-5),\n",
    "        (\"their\", (\"before\", \"X\", \"after\"), 0.0001),\n",
    "    ],\n",
    ")\n",
    "def test_bigram1_confuser_prob(my_bigram1_confuser, guess, seq, p):\n",
    "    assert my_bigram1_confuser.prob(guess, seq, 1) == pytest.approx(p, rel=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Model\n",
    "\n",
    "We can increase the context sensitivity of our model without making it too much more complicated by moving to a **trigram** model. Using the chain rule again, we have:\n",
    "\n",
    "$$\n",
    "P(\\textit{live, in, their, house, today})=P(\\textit{live})\\times P(\\textit{in}|\\textit{live})\\times \n",
    "P(\\textit{their}|\\textit{in, live})\\times\n",
    "P(\\textit{house}|\\textit{their, in})\\times\n",
    "P(\\textit{today}|\\textit{house, their})\n",
    "$$\n",
    "\n",
    "As before, we can simplify this to:\n",
    "\n",
    "$$\\begin{align}\n",
    "P(\\textit{their, house, today}|\\textit{in,live})&=P(\\textit{their}|\\textit{in, live})\\times\n",
    "P(\\textit{house}|\\textit{their, in})\\times\n",
    "P(\\textit{today}|\\textit{house, their})\\\\\n",
    "&=\\frac{C_T(\\textit{live in their})}{C_B(\\textit{live in})}\\times\n",
    "\\frac{C_T(\\textit{in their house})}{C_B(\\textit{in their})}\\times\n",
    "\\frac{C_T(\\textit{their house today})}{C_B(\\textit{their house})}\n",
    "\\end{align}$$\n",
    "\n",
    "where $C_T$ and $C_B$ are trigram and bigram frequencies.\n",
    "\n",
    "Now we implement and evaluate a trigram-based confusable solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TrigramConfuser(BigramConfuser):\n",
    "    def preprocess(self, sentence):\n",
    "        \"\"\"Normalize sentence and add filler tokens <s> and </s>\"\"\"\n",
    "        return [\"<s>\", \"<s>\"] + [w.lower() for w in sentence] + [\"</s>\", \"</s>\"]\n",
    "\n",
    "    def get_trigram_counts(self, train_corpus):\n",
    "        self.trigrams = Counter(sliding_window(3, concat(train_corpus)))\n",
    "\n",
    "    def train(self, train_corpus):\n",
    "        \"\"\"Calculate trigram frequencies in training corpus\"\"\"\n",
    "        train_corpus = [self.preprocess(sentence) for sentence in train_corpus]\n",
    "        self.get_unigram_counts(train_corpus)\n",
    "        self.get_bigram_counts(train_corpus)\n",
    "        self.get_trigram_counts(train_corpus)\n",
    "        self.get_default_guess()\n",
    "\n",
    "    def prob(self, guess, sentence, i):\n",
    "        \"\"\"Calculate probability of a guess in trigram context\"\"\"\n",
    "        try:\n",
    "            # Calculate probability with previous two words and guess\n",
    "            trigram_p1_num = self.trigrams[(sentence[i - 2], sentence[i - 1], guess)]\n",
    "            trigram_p1_den = self.bigrams[(sentence[i - 2], sentence[i - 1])]\n",
    "            p1 = trigram_p1_num / trigram_p1_den\n",
    "\n",
    "            # Calculate probability with guess, the word before it, and the word after it\n",
    "            trigram_p2_num = self.trigrams[(sentence[i - 1], guess, sentence[i + 1])]\n",
    "            trigram_p2_den = self.bigrams[(sentence[i - 1], guess)]\n",
    "            p2 = trigram_p2_num / trigram_p2_den\n",
    "            \n",
    "            # Calculate probability with guess and next two words\n",
    "            trigram_p3_num = self.trigrams[(guess, sentence[i + 1], sentence[i + 2])]\n",
    "            trigram_p3_den = self.bigrams[(guess, sentence[i + 1])]\n",
    "            p3 = trigram_p3_num / trigram_p3_den\n",
    "            \n",
    "            # Return product\n",
    "            return p1 * p2 * p3\n",
    "        except ZeroDivisionError:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we evaluate our model. How does it compare to the baseline and bigram models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.78"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_confuser = TrigramConfuser(conf_set)\n",
    "trigram_confuser.train(sentences_train)\n",
    "trigram_confuser.eval(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m13 passed\u001b[0m\u001b[32m in 0.20s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "@pytest.fixture\n",
    "def my_trigram_confuser():\n",
    "    conf = TrigramConfuser([\"their\", \"there\", \"they're\"])\n",
    "    conf.train(s.split() for s in DATA)\n",
    "    return conf\n",
    "\n",
    "def test_trigram_confuser_default(my_trigram_confuser):\n",
    "    assert my_trigram_confuser.default_guess == \"there\"\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"gram,count\",\n",
    "    [\n",
    "        ((\"<s>\", \"<s>\"), 6),\n",
    "        ((\"</s>\", \"<s>\"), 5),\n",
    "        ((\"asked\", \"whether\"), 1),\n",
    "        ((\"the\", \"pinhead\"), 0),\n",
    "    ],\n",
    ")\n",
    "def test_trigram_confuser_bi(my_trigram_confuser, gram, count):\n",
    "    assert my_trigram_confuser.bigrams[gram] == count\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"gram,count\",\n",
    "    [\n",
    "        ((\"<s>\", \"<s>\", \"</s>\"), 0),\n",
    "        ((\"</s>\", \"</s>\", \"<s>\"), 5),\n",
    "        ((\"asked\", \"whether\", \"it\"), 1),\n",
    "        ((\"zippy\", \"the\", \"pinhead\"), 0),\n",
    "    ],\n",
    ")\n",
    "def test_trigram_confuser_tri(my_trigram_confuser, gram, count):\n",
    "    assert my_trigram_confuser.trigrams[gram] == count\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"guess,seq,p\",\n",
    "    [\n",
    "        (\"there\", (\"source\", \"said\", \"X\", \"also\", \"is\"), 1.0),\n",
    "        (\"their\", (\"source\", \"said\", \"X\", \"also\", \"is\"), 0.0),\n",
    "        (\"there\", (\"sunday\", \"night\", \"X\", \"was\", \"research\"), 0.5),\n",
    "        (\"their\", (\"sunday\", \"night\", \"X\", \"was\", \"research\"), 0.0),\n",
    "    ],\n",
    ")\n",
    "def test_trigram_confuser_prob(my_trigram_confuser, guess, seq, p):\n",
    "    assert my_trigram_confuser.prob(guess, seq, 2) == pytest.approx(p, rel=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams + Add-One Smoothing\n",
    "\n",
    "Finally, we implement and evaluate a trigram model using Add-One Smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TrigramAddOneConfuser(TrigramConfuser):\n",
    "    def prob(self, guess, sentence, i):\n",
    "        V = len(self.unigrams)  # Vocabulary size\n",
    "        \n",
    "        # Calculate trigram probability with previous two words and guess\n",
    "        trigram_p1_num = self.trigrams[(sentence[i - 2], sentence[i - 1], guess)] + 1\n",
    "        trigram_p1_den = self.bigrams[(sentence[i - 2], sentence[i - 1])] + V\n",
    "        p1 = trigram_p1_num / trigram_p1_den\n",
    "        \n",
    "        # Calculate trigram probability with guess, words before it, and word after it\n",
    "        trigram_p2_num = self.trigrams[(sentence[i - 1], guess, sentence[i + 1])] + 1\n",
    "        trigram_p2_den = self.bigrams[(sentence[i - 1], guess)] + V\n",
    "        p2 = trigram_p2_num / trigram_p2_den\n",
    "        \n",
    "        # Calculate trigram probability with guess and next two words\n",
    "        trigram_p3_num = self.trigrams[(guess, sentence[i + 1], sentence[i + 2])] + 1\n",
    "        trigram_p3_den = self.bigrams[(guess, sentence[i + 1])] + V\n",
    "        p3 = trigram_p3_num / trigram_p3_den\n",
    "\n",
    "        # Return product\n",
    "        return p1 * p2 * p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.73"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram1_confuser = TrigramAddOneConfuser(conf_set)\n",
    "trigram1_confuser.train(sentences_train)\n",
    "trigram1_confuser.eval(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "@pytest.fixture\n",
    "def my_trigram1_confuser():\n",
    "    conf = TrigramAddOneConfuser([\"their\", \"there\", \"they're\"])\n",
    "    conf.train(s.split() for s in DATA)\n",
    "    return conf\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"guess,seq,p\",\n",
    "    [\n",
    "        (\"there\", (\"source\", \"said\", \"X\", \"also\", \"is\"), 2.544e-5),\n",
    "        (\"their\", (\"source\", \"said\", \"X\", \"also\", \"is\"), 9.803e-7),\n",
    "        (\"there\", (\"sunday\", \"night\", \"X\", \"was\", \"research\"), 7.688e-6),\n",
    "        (\"their\", (\"sunday\", \"night\", \"X\", \"was\", \"research\"), 9.900e-7),\n",
    "    ],\n",
    ")\n",
    "def test_trigram1_confuser_prob(my_trigram1_confuser, guess, seq, p):\n",
    "    assert my_trigram1_confuser.prob(guess, seq, 2) == pytest.approx(p, rel=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
